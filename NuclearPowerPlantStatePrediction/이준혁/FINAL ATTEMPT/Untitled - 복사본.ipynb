{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from sklearn.decomposition import KernelPCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_raw=pd.read_csv(r\"C:\\Users\\ksi03\\Downloads\\RP_data\\train_label.csv\", sep=',')\n",
    "def variable_extracter(hist):\n",
    "    loss = hist.history['loss'][0]\n",
    "    acc=hist.history['accuracy'][0]\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "def scalepca_pipeline(x, scaler):\n",
    "    x=scaler.transform(x)\n",
    "    #x=pca.transform(x)\n",
    "    return x\n",
    "\n",
    "def batch_generater(filenum, scaler, nrows=None, rate=0.9, root=r\"C:\\Users\\ksi03\\Downloads\\RP_data\\train\\\\\",):\n",
    "    y_f=[]\n",
    "    if nrows==None:\n",
    "        x_raw=pd.read_csv(root+str(filenum)+\".csv\", sep=',').values\n",
    "        #x_f=scalepca_pipeline(x_raw, scaler, pca)\n",
    "        x_f=scaler.transform(x_raw)\n",
    "        \n",
    "        y=y_raw.iloc[filenum, 1]\n",
    "        loc=10\n",
    "        for _ in range(loc):\n",
    "            y_f.append(198)\n",
    "\n",
    "        for i in range(x_f.shape[0]-loc):\n",
    "            y_f.append(y)\n",
    "    else:\n",
    "        x_raw=pd.read_csv(root+str(filenum)+\".csv\", sep=',', nrows=nrows).values\n",
    "        #x_f=scalepca_pipeline(x_raw, scaler, pca)\n",
    "        x_f=scaler.transform(x_raw)\n",
    "        \n",
    "        y=y_raw.iloc[filenum, 1]\n",
    "        loc=10\n",
    "        for stat_a in range(loc):\n",
    "            y_f.append(198)\n",
    "\n",
    "        for stat_b in range(nrows-loc):\n",
    "            y_f.append(y)\n",
    "\n",
    "        \n",
    "    y_f=np.asarray(y_f)\n",
    "    return x_f, y_f\n",
    "\n",
    "\n",
    "def scaler_pca_generater( nrows, ref_filenum=100, dim=1000):\n",
    "    #trainset인 0~745 이내에서 샘플을 100개 추출해 scaler와 pca 제작\n",
    "    filelist=random.sample(range(0, 745), ref_filenum)\n",
    "    scaler=MinMaxScaler()\n",
    "    kpca = KernelPCA(n_components=dim, kernel='rbf')\n",
    "    x_sample=[]\n",
    "    i=False\n",
    "    for num in filelist:\n",
    "        if num!=30:\n",
    "            if i!=False:\n",
    "                tmp=pd.read_csv(r\"C:\\Users\\ksi03\\Downloads\\RP_data\\train\\\\\"+str(num)+\".csv\", sep=',', nrows=nrows)\n",
    "                tmp=tmp.iloc[10:]\n",
    "                x_sample=data_raw=pd.concat([x_sample, tmp], ignore_index=True)\n",
    "            else:\n",
    "                x_sample=pd.read_csv(r\"C:\\Users\\ksi03\\Downloads\\RP_data\\train\\\\\"+str(num)+\".csv\", sep=',', nrows=nrows)\n",
    "        \n",
    "    scaler.fit(x_sample)\n",
    "    #kpca.fit(x_sample)\n",
    "    kpca=False\n",
    "    \n",
    "    del x_sample\n",
    "    return filelist, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, scaler=scaler_pca_generater(nrows=30, ref_filenum=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#828개의 dataset, 745개는 train, 43개는 valid, 40개는 test\n",
    "#valid, train=상주변수 \n",
    "#train=가변변수\n",
    "y_raw=pd.read_csv(r\"C:\\Users\\ksi03\\Downloads\\RP_data\\train_label.csv\", sep=',')\n",
    "for i in range(746, 788):\n",
    "    if i==746: \n",
    "        x_t, y_t=batch_generater(i, scaler,  nrows=30)\n",
    "        x_t=x_t[10:]\n",
    "        y_t=y_t[10:]\n",
    "    else: \n",
    "        x_t2, y_t2=batch_generater(i, scaler, nrows=30)\n",
    "        x_t2=x_t2[10:]\n",
    "        y_t2=y_t2[10:]\n",
    "        \n",
    "        x_t=np.concatenate((x_t, x_t2))\n",
    "        y_t=np.concatenate((y_t, y_t2))\n",
    "        \n",
    "y_valid=y_t\n",
    "x_valid=x_t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(789, 828):\n",
    "    if i==746: \n",
    "        x_t, y_t=batch_generater(i, scaler, nrows=30)\n",
    "        x_t=x_t[10:]\n",
    "        y_t=y_t[10:]\n",
    "    else: \n",
    "        x_t2, y_t2=batch_generater(i, scaler, nrows=30)\n",
    "        x_t2=x_t2[10:]\n",
    "        y_t2=y_t2[10:]\n",
    "        x_t=np.concatenate((x_t, x_t2))\n",
    "        y_t=np.concatenate((y_t, y_t2))\n",
    "        \n",
    "y_test=y_t\n",
    "x_test=x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid=x_valid.reshape(x_valid.shape[0], 1, x_valid.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(840, 1, 5122)\n",
      "(840,)\n",
      "(1620, 1, 5122)\n",
      "(1620,)\n"
     ]
    }
   ],
   "source": [
    "x_test=x_test.reshape(x_test.shape[0], 1, x_test.shape[1])\n",
    "\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_steps=1\n",
    "hidden_dim=10\n",
    "input_dim=5122\n",
    "init=tf.keras.initializers.he_uniform()\n",
    "reg=tf.keras.regularizers.l2(l=0.005)\n",
    "droprate = 0.3\n",
    "act='relu'\n",
    "\n",
    "L_model = tf.keras.Sequential(\n",
    "[\n",
    "tf.keras.layers.Input(shape=(input_steps, input_dim)),\n",
    "tf.keras.layers.GRU(hidden_dim ,return_state=False, kernel_initializer=init, kernel_regularizer=reg),\n",
    "tf.keras.layers.Dropout(droprate),\n",
    "#tf.keras.layers.Dense(300, activation=act),\n",
    "tf.keras.layers.Dense(30),\n",
    "tf.keras.layers.LeakyReLU(alpha=0.05),\n",
    "tf.keras.layers.Dropout(droprate),\n",
    "tf.keras.layers.Dense(10),\n",
    "tf.keras.layers.LeakyReLU(alpha=0.05),\n",
    "tf.keras.layers.Dropout(droprate),\n",
    "tf.keras.layers.GaussianNoise(0.05),\n",
    "tf.keras.layers.Dense(198, activation='softmax')])\n",
    "\n",
    "\n",
    "L_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "            #optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
    "              loss= 'sparse_categorical_crossentropy',\n",
    "              metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file0 is complete\n",
      "file1 is complete\n",
      "file2 is complete\n",
      "file3 is complete\n",
      "file4 is complete\n",
      "file5 is complete\n",
      "file6 is complete\n",
      "file7 is complete\n",
      "file8 is complete\n",
      "file9 is complete\n",
      "file10 is complete\n",
      "file11 is complete\n",
      "file12 is complete\n",
      "file13 is complete\n",
      "file14 is complete\n",
      "file15 is complete\n",
      "file16 is complete\n",
      "file17 is complete\n",
      "file18 is complete\n",
      "file19 is complete\n",
      "file20 is complete\n",
      "file21 is complete\n",
      "file22 is complete\n",
      "file23 is complete\n",
      "file24 is complete\n",
      "file25 is complete\n",
      "file26 is complete\n",
      "file27 is complete\n",
      "file28 is complete\n",
      "file29 is complete\n",
      "file31 is complete\n",
      "file32 is complete\n",
      "file33 is complete\n",
      "file34 is complete\n",
      "file35 is complete\n",
      "file36 is complete\n",
      "file37 is complete\n",
      "file38 is complete\n",
      "file39 is complete\n",
      "file40 is complete\n",
      "file41 is complete\n",
      "file42 is complete\n",
      "file43 is complete\n",
      "file44 is complete\n",
      "file45 is complete\n",
      "file46 is complete\n",
      "file47 is complete\n",
      "file48 is complete\n",
      "file49 is complete\n",
      "file50 is complete\n",
      "file51 is complete\n",
      "file52 is complete\n",
      "file53 is complete\n",
      "file54 is complete\n",
      "file55 is complete\n",
      "file56 is complete\n",
      "file57 is complete\n",
      "file58 is complete\n",
      "file59 is complete\n",
      "file60 is complete\n",
      "file61 is complete\n",
      "file62 is complete\n",
      "file63 is complete\n",
      "file64 is complete\n",
      "file65 is complete\n",
      "file66 is complete\n",
      "file67 is complete\n",
      "file68 is complete\n",
      "file69 is complete\n",
      "file70 is complete\n",
      "file71 is complete\n",
      "file72 is complete\n",
      "file73 is complete\n",
      "file74 is complete\n",
      "file75 is complete\n",
      "file76 is complete\n",
      "file77 is complete\n",
      "file78 is complete\n",
      "file79 is complete\n",
      "file80 is complete\n",
      "file81 is complete\n",
      "file82 is complete\n",
      "file83 is complete\n",
      "file84 is complete\n",
      "file85 is complete\n",
      "file86 is complete\n",
      "file87 is complete\n",
      "file88 is complete\n",
      "file89 is complete\n",
      "file90 is complete\n",
      "file91 is complete\n",
      "file92 is complete\n",
      "file93 is complete\n",
      "file94 is complete\n",
      "file95 is complete\n",
      "file96 is complete\n",
      "file97 is complete\n",
      "file98 is complete\n",
      "file99 is complete\n",
      "file100 is complete\n",
      "file101 is complete\n",
      "file102 is complete\n",
      "file103 is complete\n",
      "file104 is complete\n",
      "file105 is complete\n",
      "file106 is complete\n",
      "file107 is complete\n",
      "file108 is complete\n",
      "file109 is complete\n",
      "file110 is complete\n",
      "file111 is complete\n",
      "file112 is complete\n",
      "file113 is complete\n",
      "file114 is complete\n",
      "file115 is complete\n",
      "file116 is complete\n",
      "file117 is complete\n",
      "file118 is complete\n",
      "file119 is complete\n",
      "file120 is complete\n",
      "file121 is complete\n",
      "file122 is complete\n",
      "file123 is complete\n",
      "file124 is complete\n",
      "file125 is complete\n",
      "file126 is complete\n",
      "file127 is complete\n",
      "file128 is complete\n",
      "file129 is complete\n",
      "file130 is complete\n",
      "file131 is complete\n",
      "file132 is complete\n",
      "file133 is complete\n",
      "file134 is complete\n",
      "file135 is complete\n",
      "file136 is complete\n",
      "file137 is complete\n",
      "file138 is complete\n",
      "file139 is complete\n",
      "file140 is complete\n",
      "file141 is complete\n",
      "file142 is complete\n",
      "file143 is complete\n",
      "file144 is complete\n",
      "file145 is complete\n",
      "file146 is complete\n",
      "file147 is complete\n",
      "file148 is complete\n",
      "file149 is complete\n",
      "file150 is complete\n",
      "file151 is complete\n",
      "file152 is complete\n",
      "file153 is complete\n",
      "file154 is complete\n",
      "file155 is complete\n",
      "file156 is complete\n",
      "file157 is complete\n",
      "file158 is complete\n",
      "file159 is complete\n",
      "file160 is complete\n",
      "file161 is complete\n",
      "file162 is complete\n",
      "file163 is complete\n",
      "file164 is complete\n",
      "file165 is complete\n",
      "file166 is complete\n",
      "file167 is complete\n",
      "file168 is complete\n",
      "file169 is complete\n",
      "file170 is complete\n",
      "file171 is complete\n",
      "file172 is complete\n",
      "file173 is complete\n",
      "file174 is complete\n",
      "file175 is complete\n",
      "file176 is complete\n",
      "file177 is complete\n",
      "file178 is complete\n",
      "file179 is complete\n",
      "file180 is complete\n",
      "file181 is complete\n",
      "file182 is complete\n",
      "file183 is complete\n",
      "file184 is complete\n",
      "file185 is complete\n",
      "file186 is complete\n",
      "file187 is complete\n",
      "file188 is complete\n",
      "file189 is complete\n",
      "file190 is complete\n",
      "file191 is complete\n",
      "file192 is complete\n",
      "file193 is complete\n",
      "file194 is complete\n",
      "file195 is complete\n",
      "file196 is complete\n",
      "file197 is complete\n",
      "file198 is complete\n",
      "file199 is complete\n",
      "file200 is complete\n",
      "file201 is complete\n",
      "file202 is complete\n",
      "file203 is complete\n",
      "file204 is complete\n",
      "file205 is complete\n",
      "file206 is complete\n",
      "file207 is complete\n",
      "file208 is complete\n",
      "file209 is complete\n",
      "file210 is complete\n",
      "file211 is complete\n",
      "file212 is complete\n",
      "file213 is complete\n",
      "file214 is complete\n",
      "file215 is complete\n",
      "file216 is complete\n",
      "file217 is complete\n",
      "file218 is complete\n",
      "file219 is complete\n",
      "file220 is complete\n",
      "file221 is complete\n",
      "file222 is complete\n",
      "file223 is complete\n",
      "file224 is complete\n",
      "file225 is complete\n",
      "file226 is complete\n",
      "file227 is complete\n",
      "file228 is complete\n",
      "file229 is complete\n",
      "file230 is complete\n",
      "file231 is complete\n",
      "file232 is complete\n",
      "file233 is complete\n",
      "file234 is complete\n",
      "file235 is complete\n",
      "file236 is complete\n",
      "file237 is complete\n",
      "file238 is complete\n",
      "file239 is complete\n",
      "file240 is complete\n",
      "file241 is complete\n",
      "file242 is complete\n",
      "file243 is complete\n",
      "file244 is complete\n",
      "file245 is complete\n",
      "file246 is complete\n",
      "file247 is complete\n",
      "file248 is complete\n",
      "file249 is complete\n",
      "file250 is complete\n",
      "file251 is complete\n",
      "file252 is complete\n",
      "file253 is complete\n",
      "file254 is complete\n",
      "file255 is complete\n",
      "file256 is complete\n",
      "file257 is complete\n",
      "file258 is complete\n",
      "file259 is complete\n",
      "file260 is complete\n",
      "file261 is complete\n",
      "file262 is complete\n",
      "file263 is complete\n",
      "file264 is complete\n",
      "file265 is complete\n",
      "file266 is complete\n",
      "file267 is complete\n",
      "file268 is complete\n",
      "file269 is complete\n",
      "file270 is complete\n",
      "file271 is complete\n",
      "file272 is complete\n",
      "file273 is complete\n",
      "file274 is complete\n",
      "file275 is complete\n",
      "file276 is complete\n",
      "file277 is complete\n",
      "file278 is complete\n",
      "file279 is complete\n",
      "file280 is complete\n",
      "file281 is complete\n",
      "file282 is complete\n",
      "file283 is complete\n",
      "file284 is complete\n",
      "file285 is complete\n",
      "file286 is complete\n",
      "file287 is complete\n",
      "file288 is complete\n",
      "file289 is complete\n",
      "file290 is complete\n",
      "file291 is complete\n",
      "file292 is complete\n",
      "file293 is complete\n",
      "file294 is complete\n",
      "file295 is complete\n",
      "file296 is complete\n",
      "file297 is complete\n",
      "file298 is complete\n",
      "file299 is complete\n",
      "file300 is complete\n",
      "file301 is complete\n",
      "file302 is complete\n",
      "file303 is complete\n",
      "file304 is complete\n",
      "file305 is complete\n",
      "file306 is complete\n",
      "file307 is complete\n",
      "file308 is complete\n",
      "file309 is complete\n",
      "file310 is complete\n",
      "file311 is complete\n",
      "file312 is complete\n",
      "file313 is complete\n",
      "file314 is complete\n",
      "file315 is complete\n",
      "file316 is complete\n",
      "file317 is complete\n",
      "file318 is complete\n",
      "file319 is complete\n",
      "file320 is complete\n",
      "file321 is complete\n",
      "file322 is complete\n",
      "file323 is complete\n",
      "file324 is complete\n",
      "file325 is complete\n",
      "file326 is complete\n",
      "file327 is complete\n",
      "file328 is complete\n",
      "file329 is complete\n",
      "file330 is complete\n",
      "file331 is complete\n",
      "file332 is complete\n",
      "file333 is complete\n",
      "file334 is complete\n",
      "file335 is complete\n",
      "file336 is complete\n",
      "file337 is complete\n",
      "file338 is complete\n",
      "file339 is complete\n",
      "file340 is complete\n",
      "file341 is complete\n",
      "file342 is complete\n",
      "file343 is complete\n",
      "file344 is complete\n",
      "file345 is complete\n",
      "file346 is complete\n",
      "file347 is complete\n",
      "file348 is complete\n",
      "file349 is complete\n",
      "file350 is complete\n",
      "file351 is complete\n",
      "file352 is complete\n",
      "file353 is complete\n",
      "file354 is complete\n",
      "file355 is complete\n",
      "file356 is complete\n",
      "file357 is complete\n",
      "file358 is complete\n",
      "file359 is complete\n",
      "file360 is complete\n",
      "file361 is complete\n",
      "file362 is complete\n",
      "file363 is complete\n",
      "file364 is complete\n",
      "file365 is complete\n",
      "file366 is complete\n",
      "file367 is complete\n",
      "file368 is complete\n",
      "file369 is complete\n",
      "file370 is complete\n",
      "file371 is complete\n",
      "file372 is complete\n",
      "file373 is complete\n",
      "file374 is complete\n",
      "file375 is complete\n",
      "file376 is complete\n",
      "file377 is complete\n",
      "file378 is complete\n",
      "file379 is complete\n",
      "file380 is complete\n",
      "file381 is complete\n",
      "file382 is complete\n",
      "file383 is complete\n",
      "file384 is complete\n",
      "file385 is complete\n",
      "file386 is complete\n",
      "file387 is complete\n",
      "file388 is complete\n",
      "file389 is complete\n",
      "file390 is complete\n",
      "file391 is complete\n",
      "file392 is complete\n",
      "file393 is complete\n",
      "file394 is complete\n",
      "file395 is complete\n",
      "file396 is complete\n",
      "file397 is complete\n",
      "file398 is complete\n",
      "file399 is complete\n",
      "file400 is complete\n",
      "file401 is complete\n",
      "file402 is complete\n",
      "file403 is complete\n",
      "file404 is complete\n",
      "file405 is complete\n",
      "file406 is complete\n",
      "file407 is complete\n",
      "file408 is complete\n",
      "file409 is complete\n",
      "file410 is complete\n",
      "file411 is complete\n",
      "file412 is complete\n",
      "file413 is complete\n",
      "file414 is complete\n",
      "file415 is complete\n",
      "file416 is complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file417 is complete\n",
      "file418 is complete\n",
      "file419 is complete\n",
      "file420 is complete\n",
      "file421 is complete\n",
      "file422 is complete\n",
      "file423 is complete\n",
      "file424 is complete\n",
      "file425 is complete\n",
      "file426 is complete\n",
      "file427 is complete\n",
      "file428 is complete\n",
      "file429 is complete\n",
      "file430 is complete\n",
      "file431 is complete\n",
      "file432 is complete\n",
      "file433 is complete\n",
      "file434 is complete\n",
      "file435 is complete\n",
      "file436 is complete\n",
      "file437 is complete\n",
      "file438 is complete\n",
      "file439 is complete\n",
      "file440 is complete\n",
      "file441 is complete\n",
      "file442 is complete\n",
      "file443 is complete\n",
      "file444 is complete\n",
      "file445 is complete\n",
      "file446 is complete\n",
      "file447 is complete\n",
      "file448 is complete\n",
      "file449 is complete\n",
      "file450 is complete\n",
      "file451 is complete\n",
      "file452 is complete\n",
      "file453 is complete\n",
      "file454 is complete\n",
      "file455 is complete\n",
      "file456 is complete\n",
      "file457 is complete\n",
      "file458 is complete\n",
      "file459 is complete\n",
      "file460 is complete\n",
      "file461 is complete\n",
      "file462 is complete\n",
      "file463 is complete\n",
      "file464 is complete\n",
      "file465 is complete\n",
      "file466 is complete\n",
      "file467 is complete\n",
      "file468 is complete\n",
      "file469 is complete\n",
      "file470 is complete\n",
      "file471 is complete\n",
      "file472 is complete\n",
      "file473 is complete\n",
      "file474 is complete\n",
      "file475 is complete\n",
      "file476 is complete\n",
      "file477 is complete\n",
      "file478 is complete\n",
      "file479 is complete\n",
      "file480 is complete\n",
      "file481 is complete\n",
      "file482 is complete\n",
      "file483 is complete\n",
      "file484 is complete\n",
      "file485 is complete\n",
      "file486 is complete\n",
      "file487 is complete\n",
      "file488 is complete\n",
      "file489 is complete\n",
      "file490 is complete\n",
      "file491 is complete\n",
      "file492 is complete\n",
      "file493 is complete\n",
      "file494 is complete\n",
      "file495 is complete\n",
      "file496 is complete\n",
      "file497 is complete\n",
      "file498 is complete\n",
      "file499 is complete\n",
      "file500 is complete\n",
      "file501 is complete\n",
      "file502 is complete\n",
      "file503 is complete\n",
      "file504 is complete\n",
      "file505 is complete\n",
      "file506 is complete\n",
      "file507 is complete\n",
      "file508 is complete\n",
      "file509 is complete\n",
      "file510 is complete\n",
      "file511 is complete\n",
      "file512 is complete\n",
      "file513 is complete\n",
      "file514 is complete\n",
      "file515 is complete\n",
      "file516 is complete\n",
      "file517 is complete\n",
      "file518 is complete\n",
      "file519 is complete\n",
      "file520 is complete\n",
      "file521 is complete\n",
      "file522 is complete\n",
      "file523 is complete\n",
      "file524 is complete\n",
      "file525 is complete\n",
      "file526 is complete\n",
      "file527 is complete\n",
      "file528 is complete\n",
      "file529 is complete\n",
      "file530 is complete\n",
      "file531 is complete\n",
      "file532 is complete\n",
      "file533 is complete\n",
      "file534 is complete\n",
      "file535 is complete\n",
      "file536 is complete\n",
      "file537 is complete\n",
      "file538 is complete\n",
      "file539 is complete\n",
      "file540 is complete\n",
      "file541 is complete\n",
      "file542 is complete\n",
      "file543 is complete\n",
      "file544 is complete\n",
      "file545 is complete\n",
      "file546 is complete\n",
      "file547 is complete\n",
      "file548 is complete\n",
      "file549 is complete\n",
      "file550 is complete\n",
      "file551 is complete\n",
      "file552 is complete\n",
      "file553 is complete\n",
      "file554 is complete\n",
      "file555 is complete\n",
      "file556 is complete\n",
      "file557 is complete\n",
      "file558 is complete\n",
      "file559 is complete\n",
      "file560 is complete\n",
      "file561 is complete\n",
      "file562 is complete\n",
      "file563 is complete\n",
      "file564 is complete\n",
      "file565 is complete\n",
      "file566 is complete\n",
      "file567 is complete\n",
      "file568 is complete\n",
      "file569 is complete\n",
      "file570 is complete\n",
      "file571 is complete\n",
      "file572 is complete\n",
      "file573 is complete\n",
      "file574 is complete\n",
      "file575 is complete\n",
      "file576 is complete\n",
      "file577 is complete\n",
      "file578 is complete\n",
      "file579 is complete\n",
      "file580 is complete\n",
      "file581 is complete\n",
      "file582 is complete\n",
      "file583 is complete\n",
      "file584 is complete\n",
      "file585 is complete\n",
      "file586 is complete\n",
      "file587 is complete\n",
      "file588 is complete\n",
      "file589 is complete\n",
      "file590 is complete\n",
      "file591 is complete\n",
      "file592 is complete\n",
      "file593 is complete\n",
      "file594 is complete\n",
      "file595 is complete\n",
      "file596 is complete\n",
      "file597 is complete\n",
      "file598 is complete\n",
      "file599 is complete\n",
      "file600 is complete\n",
      "file601 is complete\n",
      "file602 is complete\n",
      "file603 is complete\n",
      "file604 is complete\n",
      "file605 is complete\n",
      "file606 is complete\n",
      "file607 is complete\n",
      "file608 is complete\n",
      "file609 is complete\n",
      "file610 is complete\n",
      "file611 is complete\n",
      "file612 is complete\n",
      "file613 is complete\n",
      "file614 is complete\n",
      "file615 is complete\n",
      "file616 is complete\n",
      "file617 is complete\n",
      "file618 is complete\n",
      "file619 is complete\n",
      "file620 is complete\n",
      "file621 is complete\n",
      "file622 is complete\n",
      "file623 is complete\n",
      "file624 is complete\n",
      "file625 is complete\n",
      "file626 is complete\n",
      "file627 is complete\n",
      "file628 is complete\n",
      "file629 is complete\n",
      "file630 is complete\n",
      "file631 is complete\n",
      "file632 is complete\n",
      "file633 is complete\n",
      "file634 is complete\n",
      "file635 is complete\n",
      "file636 is complete\n",
      "file637 is complete\n",
      "file638 is complete\n",
      "file639 is complete\n",
      "file640 is complete\n",
      "file641 is complete\n",
      "file642 is complete\n",
      "file643 is complete\n",
      "file644 is complete\n",
      "file645 is complete\n",
      "file646 is complete\n",
      "file647 is complete\n",
      "file648 is complete\n",
      "file649 is complete\n",
      "file650 is complete\n",
      "file651 is complete\n",
      "file652 is complete\n",
      "file653 is complete\n",
      "file654 is complete\n",
      "file655 is complete\n",
      "file656 is complete\n",
      "file657 is complete\n",
      "file658 is complete\n",
      "file659 is complete\n",
      "file660 is complete\n",
      "file661 is complete\n",
      "file662 is complete\n",
      "file663 is complete\n",
      "file664 is complete\n",
      "file665 is complete\n",
      "file666 is complete\n",
      "file667 is complete\n",
      "file668 is complete\n",
      "file669 is complete\n",
      "file670 is complete\n",
      "file671 is complete\n",
      "file672 is complete\n",
      "file673 is complete\n",
      "file674 is complete\n",
      "file675 is complete\n",
      "file676 is complete\n",
      "file677 is complete\n",
      "file678 is complete\n",
      "file679 is complete\n",
      "file680 is complete\n",
      "file681 is complete\n",
      "file682 is complete\n",
      "file683 is complete\n",
      "file684 is complete\n",
      "file685 is complete\n",
      "file686 is complete\n",
      "file687 is complete\n",
      "file688 is complete\n",
      "file689 is complete\n",
      "file690 is complete\n",
      "file691 is complete\n",
      "file692 is complete\n",
      "file693 is complete\n",
      "file694 is complete\n",
      "file695 is complete\n",
      "file696 is complete\n",
      "file697 is complete\n",
      "file698 is complete\n",
      "file699 is complete\n",
      "file700 is complete\n",
      "file701 is complete\n",
      "file702 is complete\n",
      "file703 is complete\n",
      "file704 is complete\n",
      "file705 is complete\n",
      "file706 is complete\n",
      "file707 is complete\n",
      "file708 is complete\n",
      "file709 is complete\n",
      "file710 is complete\n",
      "file711 is complete\n",
      "file712 is complete\n",
      "file713 is complete\n",
      "file714 is complete\n",
      "file715 is complete\n",
      "file716 is complete\n",
      "file717 is complete\n",
      "file718 is complete\n",
      "file719 is complete\n",
      "file720 is complete\n",
      "file721 is complete\n",
      "file722 is complete\n",
      "file723 is complete\n",
      "file724 is complete\n",
      "file725 is complete\n",
      "file726 is complete\n",
      "file727 is complete\n",
      "file728 is complete\n",
      "file729 is complete\n",
      "file730 is complete\n",
      "file731 is complete\n",
      "file732 is complete\n",
      "file733 is complete\n",
      "file734 is complete\n",
      "file735 is complete\n",
      "file736 is complete\n",
      "file737 is complete\n",
      "file738 is complete\n",
      "file739 is complete\n",
      "file740 is complete\n",
      "file741 is complete\n",
      "file742 is complete\n",
      "file743 is complete\n",
      "file744 is complete\n",
      "file745 is complete\n",
      "(67050, 1, 5122)\n",
      "(67050,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "_=True\n",
    "for file in range(746):\n",
    "    if file!=30:\n",
    "        x_t, y_t=batch_generater(file, scaler, nrows=100)\n",
    "        x_t=x_t[10:]\n",
    "        y_t=y_t[10:]\n",
    "\n",
    "        if _==True:\n",
    "            x_train, y_train=x_t, y_t\n",
    "        else:\n",
    "            x_train=np.concatenate((x_train, x_t))\n",
    "            y_train=np.concatenate((y_train, y_t))\n",
    "\n",
    "\n",
    "        print('file{} is complete'.format(file))\n",
    "        _=False\n",
    "    \n",
    "    \n",
    "x_train=x_train.reshape(x_train.shape[0], 1, x_train.shape[1])\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 7s 97us/sample - loss: 3.3018 - accuracy: 0.1926\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 7s 99us/sample - loss: 3.3760 - accuracy: 0.1919\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 86us/sample - loss: 3.3073 - accuracy: 0.1962\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 90us/sample - loss: 3.2742 - accuracy: 0.2005\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 88us/sample - loss: 3.3021 - accuracy: 0.2003\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 85us/sample - loss: 3.2913 - accuracy: 0.2017\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 88us/sample - loss: 3.2594 - accuracy: 0.1997\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 88us/sample - loss: 3.2414 - accuracy: 0.2022\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 87us/sample - loss: 3.2050 - accuracy: 0.1990\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 86us/sample - loss: 3.1873 - accuracy: 0.2000\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 86us/sample - loss: 3.2744 - accuracy: 0.1963\n",
      "[step: 10]'s cost = 3.274370672985478   acc=0.19630126655101776\n",
      "New best known cost = 4.695433662051246, acc=0.21904762089252472\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 86us/sample - loss: 3.2367 - accuracy: 0.1984\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 82us/sample - loss: 3.2744 - accuracy: 0.1997\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 84us/sample - loss: 3.2817 - accuracy: 0.1997\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 91us/sample - loss: 3.2365 - accuracy: 0.2014\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 92us/sample - loss: 3.2131 - accuracy: 0.2019\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 90us/sample - loss: 3.2386 - accuracy: 0.2027\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 89us/sample - loss: 3.1934 - accuracy: 0.2041\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 87us/sample - loss: 3.2065 - accuracy: 0.2003\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 86us/sample - loss: 3.1717 - accuracy: 0.2024\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 88us/sample - loss: 3.2482 - accuracy: 0.2018\n",
      "[step: 20]'s cost = 3.248180519014397   acc=0.20180462300777435\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 84us/sample - loss: 3.2579 - accuracy: 0.1978\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 89us/sample - loss: 3.2455 - accuracy: 0.1955\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 87us/sample - loss: 3.2356 - accuracy: 0.2031\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 89us/sample - loss: 3.3101 - accuracy: 0.2041\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 80us/sample - loss: 3.2605 - accuracy: 0.2049\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 84us/sample - loss: 3.2619 - accuracy: 0.2008\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 79us/sample - loss: 3.2511 - accuracy: 0.1993\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 86us/sample - loss: 3.2252 - accuracy: 0.2016\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 89us/sample - loss: 3.1897 - accuracy: 0.2025\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 81us/sample - loss: 3.2268 - accuracy: 0.2035\n",
      "[step: 30]'s cost = 3.226774352242216   acc=0.2035197615623474\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 85us/sample - loss: 3.3217 - accuracy: 0.2051\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 80us/sample - loss: 3.2029 - accuracy: 0.2062\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 80us/sample - loss: 3.1694 - accuracy: 0.2041\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 88us/sample - loss: 3.1895 - accuracy: 0.2065\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 88us/sample - loss: 3.1485 - accuracy: 0.2110\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 87us/sample - loss: 3.1383 - accuracy: 0.2102\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 96us/sample - loss: 3.1516 - accuracy: 0.2075\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 90us/sample - loss: 3.1670 - accuracy: 0.2076\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 89us/sample - loss: 3.3154 - accuracy: 0.2020\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 82us/sample - loss: 3.1825 - accuracy: 0.2048\n",
      "[step: 40]'s cost = 3.18246997709509   acc=0.20477256178855896\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 93us/sample - loss: 3.1344 - accuracy: 0.2109\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 93us/sample - loss: 3.3065 - accuracy: 0.2052\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 86us/sample - loss: 3.2311 - accuracy: 0.2039\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 86us/sample - loss: 3.2037 - accuracy: 0.2078\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 84us/sample - loss: 3.1495 - accuracy: 0.2119\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 86us/sample - loss: 3.2285 - accuracy: 0.2071\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 80us/sample - loss: 3.1984 - accuracy: 0.2055\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 86us/sample - loss: 3.1227 - accuracy: 0.2125\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 88us/sample - loss: 3.1681 - accuracy: 0.2169\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 81us/sample - loss: 3.1351 - accuracy: 0.2176\n",
      "[step: 50]'s cost = 3.1350891243424726   acc=0.2175988107919693\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 85us/sample - loss: 3.1591 - accuracy: 0.2144\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 84us/sample - loss: 3.1300 - accuracy: 0.2181\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 80us/sample - loss: 3.1919 - accuracy: 0.2136\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 80us/sample - loss: 3.1589 - accuracy: 0.2168\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 83us/sample - loss: 3.1308 - accuracy: 0.2136\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 87us/sample - loss: 3.1199 - accuracy: 0.2156\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 84us/sample - loss: 3.1348 - accuracy: 0.2149\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 85us/sample - loss: 3.2033 - accuracy: 0.2080\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 81us/sample - loss: 3.2154 - accuracy: 0.2109\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 80us/sample - loss: 3.1689 - accuracy: 0.2091\n",
      "[step: 60]'s cost = 3.168874542185124   acc=0.20908276736736298\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 85us/sample - loss: 3.1751 - accuracy: 0.2082\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 84us/sample - loss: 3.1538 - accuracy: 0.2156\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 79us/sample - loss: 3.1299 - accuracy: 0.2156\n",
      "Train on 67050 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67050/67050 [==============================] - 5s 81us/sample - loss: 3.1285 - accuracy: 0.2194\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 86us/sample - loss: 3.1491 - accuracy: 0.2181\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 81us/sample - loss: 3.1363 - accuracy: 0.2159\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 84us/sample - loss: 3.1127 - accuracy: 0.2177\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 85us/sample - loss: 3.1706 - accuracy: 0.2109\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 80us/sample - loss: 3.0909 - accuracy: 0.2155\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 83us/sample - loss: 3.0497 - accuracy: 0.2206\n",
      "[step: 70]'s cost = 3.0496731236477026   acc=0.22062639892101288\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 83us/sample - loss: 3.1044 - accuracy: 0.2208\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 81us/sample - loss: 3.0839 - accuracy: 0.2232\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 83us/sample - loss: 3.0202 - accuracy: 0.2247\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 80us/sample - loss: 3.0554 - accuracy: 0.2264\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 84us/sample - loss: 3.1559 - accuracy: 0.2257\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 79us/sample - loss: 3.0950 - accuracy: 0.2214\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 80us/sample - loss: 3.1103 - accuracy: 0.2209\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 84us/sample - loss: 3.1556 - accuracy: 0.2228\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 84us/sample - loss: 3.0995 - accuracy: 0.2233\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 80us/sample - loss: 3.0553 - accuracy: 0.2243\n",
      "[step: 80]'s cost = 3.055344804554711   acc=0.22429530322551727\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 80us/sample - loss: 3.1471 - accuracy: 0.2263\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 80us/sample - loss: 3.4252 - accuracy: 0.2110\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 80us/sample - loss: 3.1326 - accuracy: 0.2176\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 90us/sample - loss: 3.1034 - accuracy: 0.2288\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 86us/sample - loss: 3.1395 - accuracy: 0.2306\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 85us/sample - loss: 3.1169 - accuracy: 0.2269s - loss:\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 85us/sample - loss: 3.1060 - accuracy: 0.2309\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 80us/sample - loss: 3.0645 - accuracy: 0.2304\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 80us/sample - loss: 3.0478 - accuracy: 0.2321\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 83us/sample - loss: 3.0519 - accuracy: 0.2296\n",
      "[step: 90]'s cost = 3.0518928667576253   acc=0.22957494854927063\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 89us/sample - loss: 3.2246 - accuracy: 0.2074\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 85us/sample - loss: 3.1754 - accuracy: 0.2092\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 81us/sample - loss: 3.1544 - accuracy: 0.2048\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 85us/sample - loss: 3.1567 - accuracy: 0.2091\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 85us/sample - loss: 3.1396 - accuracy: 0.2104\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 84us/sample - loss: 3.1060 - accuracy: 0.2154\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 80us/sample - loss: 3.0791 - accuracy: 0.2241\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 5s 79us/sample - loss: 3.1297 - accuracy: 0.2179\n",
      "Train on 67050 samples\n",
      "67050/67050 [==============================] - 6s 86us/sample - loss: 3.0867 - accuracy: 0.2207\n",
      "--- 학습 종료 ---\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "##러닝\n",
    "current_cost_train = 1000 #초기 값으로 높은 값 부여\n",
    "current_cost_valid = 1000 #초기 값으로 높은 값 부여\n",
    "known_best = 1000 #초기 값으로 높은 값 부여\n",
    "full_step = 11\n",
    "best_model=0\n",
    "acc=0\n",
    "trainValues=[]\n",
    "validValues=[]\n",
    "\n",
    "\n",
    "for file in range(100): #100회의 파일\n",
    "    if file!=None:\n",
    "        train_hist = L_model.fit(x_train, y_train, batch_size=300, verbose=1)\n",
    "        loss, acc = variable_extracter(train_hist)\n",
    "\n",
    "        gc.collect()\n",
    "        \n",
    "        if (file > 0 and file % 10 == 0): #매 10번째 학습 성능 값 출력\n",
    "            print(\"[step: {}]'s cost = {}   acc={}\".format(file, loss, acc)) \n",
    "            if (file >= 0): #1000번째부터 검증데이터로 모델 성능 평가\n",
    "                current_cost_valid = L_model.evaluate(x_valid, y_valid,batch_size=100, verbose=0)\n",
    "                gc.collect()\n",
    "                trainValues.append(loss) #학습 곡선을 출력하기 위해 현재 값 저장\n",
    "                validValues.append(current_cost_valid[0]) #검증 곡선을 출력하기위해 현재 값 저장\n",
    "\n",
    "                if (current_cost_valid[0] < known_best): #검증 성능이 이전보다 좋을 경우 현재 모델 저장\n",
    "                    known_best = current_cost_valid[0]\n",
    "                    best_model=L_model\n",
    "                    print(\"New best known cost = {}, acc={}\".format(known_best, current_cost_valid[1]))\n",
    "\n",
    "        #print(\"학습루틴 {}회 종료\".format(file))\n",
    "\n",
    "\n",
    "##\n",
    "print(\"--- 학습 종료 ---\")\n",
    "\n",
    "label_model=best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.695433662051246,\n",
       " 5.100802455629621,\n",
       " 4.721762975056966,\n",
       " 4.987508648917789,\n",
       " 4.886150632585798,\n",
       " 5.350240815253485,\n",
       " 5.538573662439982,\n",
       " 5.910315161659604,\n",
       " 6.34857173760732]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train.shape[0]\n",
    "#이렇게 돌린 모델과 다른 모델 비교하기\n",
    "ref='100b_1'\n",
    "L_model.save(r\"C:\\\\Users\\ksi03\\model\\mod2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.396516463491651\n",
      "0.245679\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n"
     ]
    }
   ],
   "source": [
    "L_model=tf.keras.models.load_model(r\"C:\\\\Users\\ksi03\\model\\mod2.h5\")\n",
    "testcost=L_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(testcost[0])\n",
    "print(testcost[1])\n",
    "y_tmp=[]\n",
    "y_final=[]\n",
    "_=True\n",
    "for num in range(828, 1548):\n",
    "    if num!=1154 and num!=1168:\n",
    "        \n",
    "        x_raw=pd.read_csv(r'C:\\Users\\ksi03\\Downloads\\RP_data\\test\\\\'+str(num)+\".csv\", sep=',', nrows=30).values\n",
    "        x_raw=x_raw[10:]\n",
    "        x_real=scalepca_pipeline(x_raw, scaler)\n",
    "        x_real=x_real.reshape(x_real.shape[0], 1, x_real.shape[1])\n",
    "        \n",
    "        y_real=L_model.predict(x_real,batch_size=1, verbose=0) \n",
    "        \n",
    "        y_tmp=[]\n",
    "        for i in range(y_real.shape[0]):\n",
    "            y_tmp.append(np.argmax((y_real[i])))\n",
    "             \n",
    "\n",
    "        y_final.append([num, str(np.argmax(np.bincount(np.array(y_tmp))))])\n",
    "        print(num)  \n",
    "    else:\n",
    "        y_final.append([num, str(np.argmax(np.bincount(np.array(y_tmp))))])\n",
    "        print(num)  \n",
    "                         \n",
    "            \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 2)\n"
     ]
    }
   ],
   "source": [
    "y_tmp=np.array(y_final)\n",
    "print(y_tmp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['828', '111'],\n",
       "       ['829', '118'],\n",
       "       ['830', '110'],\n",
       "       ...,\n",
       "       ['1545', '168'],\n",
       "       ['1546', '110'],\n",
       "       ['1547', '110']], dtype='<U11')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(y_tmp, columns=['num','label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 41)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dummy = pd.get_dummies(y, columns=['label'])\n",
    "y_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dummy.to_csv('.\\y2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
